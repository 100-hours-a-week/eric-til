# 동시성

- 정의 : 하나의 CPU에서 여러 작업이 동시에 실행되는 것처럼 보이게 하는 개념. 논리적. 실제로 동시에 처리되는 것은 아님
- OS가 스케쥴링을 통해 여러 작업을 효율적으로 처리할 수 있도록 함. 단일 CPU 환경에서 시스템 자원을 효과적으로 활용
- 특징
    - 작업 간 전환(컨텍스트 스위칭) : 여러 작업 빠르게 전환하며 실행
    - 자원 공유 : 여러 작업이 동일한 CPU와 메모리 공유하며 동작
    - 운영체제의 역할 : 스케쥴링을 통해 작업 실행 순서 조정
    - 적용 분야 : I/O 중심 작업(파일 입출력, 네트워크 처리) 효과적

### 알아야 하는 이유

- 백엔드 서버에서 적절히 자원 관리. 사용자는 빠른 응답 속도 경험 가능. CPU가 대기 상태로 안가고 연속적으로 작업 처리
- 동시성 안쓰는 것은 창구 하나만 열어놓는 것이랑 똑같음

### 동작방식

- 작업을 작은 단위로 나누어 짧은 실행 시간을 할당하고, 스케줄러가 이를 관리하여 컨텍스트 스위칭 실시

1. 작업 분할 : 작업을 작은 단위로 나눔
2. 시간 할당 : 각 단위에 짧은 시간을 할당하여 순차적으로 실행
3. 컨텍스트 스위칭 : 전환 시 상태를 저장하고 다시 실행 시 상태를 복원하여 중단없이 실행
    - 전환하는 것에 오버헤드가 발생하기 때문에 너무 잦으면 좋지 않음

### 동시성 구현 예시

#### 스레드풀

자바

- 스레드를 매번 새롭게 만드는 것은 오버헤드가 큼
-> 미리 스레드를 여러개 만들어놓고 재활용함으로 오버헤드를 줄임

#### 싱글 스레드 기반의 이벤트 루프

- Node.js

---

# 병렬성

- 다중 코어/프로세서를 활용하여 여러 작업을 물리적으로 실행하는 기술
- CPU 자원을 최대한 활용하여, 실시간 처리와 대규모 데이터 처리에 좋음
- 하드웨어의 지원이 필요함
- 특징 :
    - 하드웨어 의존적 : 다중 코어 CPU, 다중 프로세서 지원을 필요로함
    - 작업의 독립성 : 작업이 서로 간섭없이 실행
    - 계산 중심 : 대규모 데이터 처리, 연산 중심 작업, 병렬 알고리즘
    - 성능 향상 : 코어 수가 많을수록 많은 작업 처리 가능

### 알아야하는 이유

1. 실시간 처리 사용자 경험 개선 :
    - 병렬성을 통해 실시간 시스템(게임, 스트리밍)에서 지연 없이 처리되도록 만들어 사용자 경험 극대화
2. 대규모 데이터 처리 속도 극대화 :
    - 대규모 작업 빠르고 효율적으로 수행
3. 자원 활용 극대화 :
    - 자원 최대한 활용하여 최적 성능 달성 가능

### 동작 방식

1. 작업 분할 : 실행할 작업을 독립적인 단위로 나눔
2. 자원 할당 : 작업에 대해 사용 가능한 CPU 코어, 메모리 등 자원 할당
3. 병렬 실행 : 각 작업이 독립적으로 실행
4. 결과 통합 : 각 작업의 결과를 취합하여 사용자에게 최종적으로 전달
5. 오류 및 복구 관리 : 병렬 처리 도중 오류가 발생하면 재시도하거나 해결하여 작업 진행 보장

### 동시성과 병렬성의 관계

- 둘은 유사하게 보이지만 본질적으로 다른 개념.
- 동시성은 작업 전환을 통해 하나의 CPU에서도 여러 작업이 마치 동시에 실행되는 것처럼 보이게 하는 반면, 병렬성은 여러 CPU 코어에서 작업이 실제로 동시에 실행되는 방식
- 하나만 쓰는게 아니라, 둘 다 사용해서 성능 극대화시켜야됨

---

# 스케줄러

- 정의 : OS 핵심 구성 요소로 CPU와 같은 시스템 자원을 적절히 분배하기 위해 프로세스나 스레드 실생 순서 관리
- 기능 :
    1. 작업 선택
        - 실행 가능한 작업 중에서 어떤 작업을 실행할지 결정
        - 스케줄링 알고리즘을 통해 우선순위 높은 작업
    2. 자원 분배
        - CPU 같은 자원을 공평하게 사용할 수 있도록 분배
        - 작업에 짧은 시간(타임 슬라이스)를 할당하고 실행
    3. 컨텍스트 스위칭 관리
        - 전환 시 이전 작업의 상태(레지스터, 프로그램 카운터 등)를 저장하고, 새로운 작업의 상태 복원하여 중단없이 진행되도록 함
- 종류 (참고)
    - 장기 스케줄러 : 작업 총량 결정
        - 디스크에서 메모리로 로드할 작업을 선택
    - 중기 스케줄러 : 메모리에 있는 작업 중 어떤 작업 중단할지 결정
        - 메모리가 부족할 경우 비활성 작업을 디스크로 이동시켜 자원 확보
    - 단기 스케줄러 : 실행 가능할 작업 중 CPU 사용할 작업 결정
        - 실행 가능한 작업 중 CPU를 점유할 작업을 선택하여 빠르게 실행

### 사용 이유

- 시스템 성능 최적화. 사용자 경험 개선. 시스템 공정성 보장
- CPU 이용률 최대화
- 처리량 최대화
- 총 처리 시간 최소화
- 대기 시간 최소화
- 응답 시간 최소화

### 사용 방법

- 스케줄러 동작 방식
    1. 작업 대기열 관리 : 실행 대기 중인 작업 대기열(큐)에 배치
    2. 우선순위 설정 : 작업의 우선 순위를 분석해 실행 순서 결정
    3. 자원 분배 : 작업에 필요한 CPU 시간, 메모리 공간 할당
    4. 작업 전환 : 컨텍스트 스위칭 수행
    5. 완료 및 자원 해제 : 작업 완료 후 자원 해제하여 다른 작업 사용 준비

## 라운드 로빈

여기서 말하는 큐는 준비 큐

- RR은 프로세스들 사이 우선 순위를 두지 않고 순서대로 CPU를 할당. 한 프로세스 당 일정 시간(time quantum)만 수행 한 뒤 시간이 끝나면 큐의 맨 뒤로 보내버림.

## 콘보이 현상

여기서 말하는 큐는 준비 큐

- 작업 시간이 긴 프로세스가 큐에 먼저 도착해서 다른 프로세스의 실행 시간을 늦추는 것을 말함. FCFS 스케줄링에서 발생될 수 있음

## 비선점/선점

여기서 말하는 큐는 준비 큐

- 스케줄링 방식에는 비선점 스케줄링과 선점 스케줄링이 있음
    - 비선점 : 이미 할당된 CPU를 다른 프로세스가 강제로 뺏을 수 없는
        - FCFS
            - 프로세스가 도착하는 순서대로 CPU를 할당 받음
        - SJF
            - 큐에서 기다리고 있는 프로세스 중 가장 실행 시간이 짧은 프로세스가 할당 받음
        - HRN
            - (대기시간 + 서비스(실행)시간) / 서비스(실행)시간 계산 값이 큰 프로세스가 할당 받음
    - 선점 : 우선 순위가 높은 프로세스가 뺏을 수 있는
        - SRT
            - 가장 짧은 프로세스가 할당 받음. 실행 중인 프로세스보다 짧으면 뺏김
        - RR
            - 도착하는 순서대로 할당 받고 정해진 시간동안 처리되고 완료되지 않으면 큐의 맨 뒤로 이동
        - MQ
            - 프로세스를 분류하여 여러 개의 큐로 분리함. 큐마다 우선 순위가 다름. 각 큐에서는 그들만의 스케줄링을 사용.

## 컨텍스트 스위칭

- CPU/코어에서 실행 중이던 프로세스/스레드가 다른 프로세스/스레드로 교체되는 것

- 언제 발생하는가?
    - 주어진 Time Slice(Time Quantum)를 다 사용함
    - I/O 작업을 해야 함
    - 다른 리소스를 기다려야 함
    - 인터럽트(Interrupt)

---

# 암달의 법칙

- 프로그램은 병렬처리가 가능한 부분과 불가능한 순차적인 부분으로 구성되므로 프로세서를 아무리 병렬화 시켜도 더 이상 성능이 향상되지 않는 한계가 존재한다는 법칙

1 / ((1-P) * P / S)

(1-P)는 병렬처리가 불가능한 부분, P는 병렬처리가 가능한 부분, S는 프로세서의 개수

P가 95%라고 하고 S를 무한대라고 하자. 최대로 속도향상이 가능한 임계점을 계산해보면
 `1/(1-0.95) = 20` . 즉 프로세서를 아무리 늘려봤자 20배가 최대 향상이라는 뜻

---

# c10k 문제

- 동시 사용자 1만명(Concurrent 10K users) 접속하는 서버를 구현하는 문제.
- 단순히 스레드 1만개를 만들어서 해결하기에는 컨텍스트 스위칭 과정에서 경합이 발생. 그럼 성능 저하의 문제가 생길 수 있음
- 논블로킹과 비동기를 통해 해결.
    - epoll(), kqueue() 등으로 문제를 해결할 수 있음
    - Node.js나 nginx에서 사용하고 있음. 블랙박스.

---

# 동시성과 병렬성의 차이, 멀티 쓰레드에서의 동시성과 병렬성

- 동시성은 여러 작업이 동시에 실행되는 것처럼 보이는 개념. 논리적인 동시 실행
하나의 CPU
- 병렬성은 실제로 여러 작업이 동시에 실행됨. 물리적인 동시 실행
멀티코어

---

- 멀티 쓰레드 환경에서 동시성
    - 여러 쓰레드가 하나의 CPU 코어에서 번갈아가며 실행.
- 멀티 쓰레드 환경에서 병렬성
    - 여러 쓰레드가 멀티 코어에서 동시에 실행

---

# 컨텍스트 스위칭이 발생할 때 생기는 부정적인 영향에 대해서 설명해주세요

- 성능 저하
    - 레지스터, 프로그램 카운터, 스택 포인터 등 상태 정보를 저장하고 복원하는데 이 과정에서 CPU 사이클이 소모되어 성능 저하
- 시스템 자원 낭비
    - 작업의 상태 정보를 저장하기 위해 메모리 공간이 필요함. 스레드나 프로세스가 많아질수록 메모리 오버헤드 증가
- 응답 시간 증가
    - 컨텍스트 스위칭이 잦으면, 응답 시간이 증가할 수 있음
    - race condition이나 deadlock이 발생할 가능성있음
    
    ---
    

# 스레드풀을 사용하는 이유와 장단점에 대해서 설명해주세요

- 사용하는 이유
    - 스레드 생성 비용 절감 : 재사용함으로써 스레드 생성, 삭제 과정 오버헤드를 줄이기 위해서
    - 자원 관리 및 제어 : 최대 스레드 수를 제한하여 자원 고갈을 막을 수 있음
    - race condition이나 deadlock 발생 가능성을 낮출 수 있음

- 장점 :
    - 사용하는 이유들이 장점임

- 단점 :
    - 적절한 풀 크기 설정 해야함 : 너무 작으면 느려지고, 너무 크면 자원 고갈됨
    - 스레드 풀 내의 스레드에 잠을 자거나, I/O를 기다리거나 네트워크 연결 등을 기다리는 태스크가 있으면 성능이 급격히 저하함.
    - 너무 많은 스레드가 대기 상태로 유지될 경우 자원 낭비 가능성이 있음

---

# 프로세스 스케쥴링과 스레드 스케쥴링의 차이점에 대해서 설명해주세요

- 다른 프로세스끼리의 스위칭과 같은 프로세스의 스레드끼리의 스위칭이 있음
    - 다른 프로세스 스위칭
        - 서로 다른 프로세스는 **메모리 주소 체계**가 다르기 때문에, 컨텍스트 스위칭 시 이에 관련된 아래의 처리가 추가됨
        
        - **MMU**(Memory Management Unit)는 가상 메모리 주소를 물리 메모리 주소로 변환하는 역할을 하며, 이를 통해 각 프로세스는 자신만의 가상 주소 공간을 사용
        - **TLB**(Translation Lookaside Buffer)는 MMU의 주소 변환 속도를 높이기 위한 캐시로, 이전 프로세스의 주소 변환 정보가 저장되어 있음
        - 따라서 프로세스 스위칭 시 **TLB 플러시**(TLB를 비우는 작업)를 수행하여 이전 프로세스의 주소 변환 정보가 남아있지 않도록 해야 함
        
    - 스레드끼리의 스위칭
        - 실행되고 있던 스레드의 상태를 저장하고, 새로 실행될 스레드의 상태를 로딩
